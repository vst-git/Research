{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7JvEPi7657z",
        "outputId": "5edf041d-5d1b-437f-a127-0648f6a7f389"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.4)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=0b187ab4d73334eba8437d7c07fa2b5d4053d91e28293e485709596441e0f8a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import cv2\n",
        "from imutils import paths\n",
        "import face_recognition\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "from imutils import build_montages\n",
        "import collections"
      ],
      "metadata": {
        "id": "fL1wS6SF5nqA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"/content/summerProj\")\n",
        "os.mkdir(\"/content/summerProj/videos\")\n",
        "os.mkdir(\"/content/summerProj/videos/videoFrames\")\n",
        "os.mkdir(\"/content/summerProj/static\")\n",
        "os.mkdir(\"/content/summerProj/static/faces\")\n",
        "os.mkdir(\"/content/summerProj/static/foundFaces\")"
      ],
      "metadata": {
        "id": "vIxThPqn7Z6H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2. CascadeClassifier (cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
      ],
      "metadata": {
        "id": "_Il2V6Y170M9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createFaceFrames(address,destin):\n",
        "    vid = cv2.VideoCapture(address)\n",
        "    count = 0\n",
        "    frameCount = 0\n",
        "    while vid.isOpened():\n",
        "        frameCount+=1\n",
        "        success,img = vid.read()\n",
        "        if not success:\n",
        "            break\n",
        "        if frameCount%30 != 0:\n",
        "            continue\n",
        "        print(f\"imageNum {count}\")\n",
        "        faces = face_cascade.detectMultiScale(img,1.3,4)\n",
        "        if len(faces):\n",
        "            count+=1\n",
        "            cv2.imwrite(f\"/content/summerProj/videos/videoFrames/{destin}_{count}.jpg\",img)\n",
        "    return frameCount\n"
      ],
      "metadata": {
        "id": "4DJmXyvN7Tmg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/summerProj/videos/videoFrames'\n",
        "for f in os.listdir(dir):\n",
        "    os.remove(os.path.join(dir, f))\n",
        "start = time.time()\n",
        "imgCount1 = createFaceFrames(\"/content/summerProj/videos/destinVideo.mov\",\"destin\")\n",
        "end = time.time()\n",
        "print(f\"sample lenght: {imgCount1/30} sec\")\n",
        "print(f\"Time for generating the frames of destinVideo: {end-start} sec\")\n",
        "start = time.time()\n",
        "imgCount2 = createFaceFrames(\"/content/summerProj/videos/sourceVideo.mov\",\"source\")\n",
        "end = time.time()\n",
        "print(f\"sample lenght: {imgCount2/30} sec\")\n",
        "print(f\"Time for generating the frames of sourceVideo: {end-start} sec\")"
      ],
      "metadata": {
        "id": "SbWW7YMl8Du9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf9c962-80d1-484d-c2f7-da2ce22a6555"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imageNum 0\n",
            "imageNum 0\n",
            "imageNum 0\n",
            "imageNum 0\n",
            "imageNum 1\n",
            "imageNum 1\n",
            "imageNum 1\n",
            "imageNum 1\n",
            "imageNum 2\n",
            "imageNum 2\n",
            "imageNum 3\n",
            "imageNum 4\n",
            "imageNum 4\n",
            "imageNum 5\n",
            "imageNum 6\n",
            "imageNum 7\n",
            "imageNum 7\n",
            "imageNum 7\n",
            "imageNum 8\n",
            "imageNum 9\n",
            "imageNum 10\n",
            "imageNum 11\n",
            "imageNum 12\n",
            "imageNum 13\n",
            "imageNum 14\n",
            "imageNum 15\n",
            "imageNum 16\n",
            "imageNum 17\n",
            "imageNum 17\n",
            "imageNum 17\n",
            "imageNum 18\n",
            "imageNum 19\n",
            "imageNum 20\n",
            "imageNum 21\n",
            "imageNum 21\n",
            "imageNum 22\n",
            "imageNum 22\n",
            "imageNum 22\n",
            "imageNum 23\n",
            "imageNum 24\n",
            "imageNum 25\n",
            "imageNum 26\n",
            "imageNum 27\n",
            "imageNum 28\n",
            "imageNum 29\n",
            "imageNum 29\n",
            "imageNum 30\n",
            "imageNum 31\n",
            "imageNum 32\n",
            "imageNum 33\n",
            "imageNum 33\n",
            "imageNum 33\n",
            "imageNum 34\n",
            "imageNum 35\n",
            "imageNum 35\n",
            "imageNum 35\n",
            "imageNum 36\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 37\n",
            "imageNum 38\n",
            "imageNum 39\n",
            "imageNum 39\n",
            "imageNum 39\n",
            "imageNum 40\n",
            "imageNum 41\n",
            "imageNum 41\n",
            "imageNum 42\n",
            "imageNum 42\n",
            "imageNum 43\n",
            "imageNum 44\n",
            "imageNum 45\n",
            "imageNum 45\n",
            "imageNum 46\n",
            "imageNum 46\n",
            "imageNum 47\n",
            "imageNum 48\n",
            "imageNum 48\n",
            "imageNum 48\n",
            "imageNum 48\n",
            "imageNum 49\n",
            "imageNum 49\n",
            "imageNum 50\n",
            "imageNum 50\n",
            "imageNum 51\n",
            "imageNum 52\n",
            "imageNum 53\n",
            "imageNum 54\n",
            "imageNum 55\n",
            "imageNum 56\n",
            "imageNum 57\n",
            "imageNum 58\n",
            "imageNum 59\n",
            "imageNum 59\n",
            "imageNum 59\n",
            "imageNum 60\n",
            "imageNum 60\n",
            "imageNum 61\n",
            "imageNum 62\n",
            "imageNum 63\n",
            "imageNum 63\n",
            "imageNum 63\n",
            "imageNum 63\n",
            "imageNum 63\n",
            "imageNum 64\n",
            "imageNum 65\n",
            "imageNum 66\n",
            "imageNum 67\n",
            "imageNum 68\n",
            "imageNum 68\n",
            "imageNum 69\n",
            "imageNum 70\n",
            "imageNum 71\n",
            "imageNum 72\n",
            "imageNum 73\n",
            "imageNum 74\n",
            "imageNum 75\n",
            "imageNum 76\n",
            "imageNum 77\n",
            "imageNum 78\n",
            "imageNum 79\n",
            "imageNum 80\n",
            "imageNum 81\n",
            "imageNum 82\n",
            "imageNum 83\n",
            "imageNum 84\n",
            "imageNum 85\n",
            "imageNum 86\n",
            "imageNum 87\n",
            "imageNum 88\n",
            "imageNum 89\n",
            "imageNum 90\n",
            "imageNum 91\n",
            "imageNum 92\n",
            "imageNum 92\n",
            "imageNum 93\n",
            "imageNum 94\n",
            "imageNum 94\n",
            "imageNum 94\n",
            "imageNum 95\n",
            "imageNum 96\n",
            "imageNum 97\n",
            "imageNum 97\n",
            "imageNum 97\n",
            "imageNum 97\n",
            "imageNum 98\n",
            "imageNum 99\n",
            "imageNum 99\n",
            "imageNum 99\n",
            "imageNum 100\n",
            "imageNum 101\n",
            "imageNum 101\n",
            "imageNum 102\n",
            "imageNum 102\n",
            "imageNum 102\n",
            "imageNum 102\n",
            "imageNum 102\n",
            "sample lenght: 163.3 sec\n",
            "Time for generating the frames of destinVideo: 59.68471097946167 sec\n",
            "imageNum 0\n",
            "imageNum 1\n",
            "imageNum 2\n",
            "imageNum 3\n",
            "imageNum 4\n",
            "imageNum 5\n",
            "imageNum 6\n",
            "imageNum 7\n",
            "imageNum 8\n",
            "imageNum 9\n",
            "imageNum 10\n",
            "imageNum 11\n",
            "imageNum 12\n",
            "imageNum 13\n",
            "imageNum 14\n",
            "imageNum 15\n",
            "imageNum 16\n",
            "imageNum 16\n",
            "imageNum 17\n",
            "imageNum 17\n",
            "imageNum 18\n",
            "sample lenght: 21.233333333333334 sec\n",
            "Time for generating the frames of sourceVideo: 36.755366802215576 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"using hog\")\n",
        "start = time.time()\n",
        "dir = '/content/summerProj/static/faces'\n",
        "for f in os.listdir(dir):\n",
        "    os.remove(os.path.join(dir, f))\n",
        "data = []\n",
        "imagePaths = list(paths.list_images(\"/content/summerProj/videos/videoFrames\"))\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "    print(\"processing image: \",i)\n",
        "    image = cv2.imread(imagePath)\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    boxes = face_recognition.face_locations(rgb, model=\"hog\")\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "    d = [{\"imagePath\": imagePath, \"loc\": box, \"encoding\": enc} for (box, enc) in zip(boxes, encodings)]\n",
        "    data.extend(d)\n",
        "data = np.array(data)\n",
        "encodings = [d[\"encoding\"] for d in data]\n",
        "end = time.time()\n",
        "print(\"sample size: \",len(encodings),\" faces\")\n",
        "print(\"time of encoding generation:\", end-start,\" sec\")\n",
        "start = time.time()\n",
        "clt = DBSCAN(metric=\"euclidean\", n_jobs=-1)\n",
        "clt.fit(encodings)\n",
        "end = time.time()\n",
        "print(\"time of clustering:\", end-start,\" sec\")\n",
        "labels = clt.labels_\n",
        "labelIDs = np.unique(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj1SrJvX9MBS",
        "outputId": "e08e0fa1-3cbf-4a1f-cd47-468741655378"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using hog\n",
            "processing image:  0\n",
            "processing image:  1\n",
            "processing image:  2\n",
            "processing image:  3\n",
            "processing image:  4\n",
            "processing image:  5\n",
            "processing image:  6\n",
            "processing image:  7\n",
            "processing image:  8\n",
            "processing image:  9\n",
            "processing image:  10\n",
            "processing image:  11\n",
            "processing image:  12\n",
            "processing image:  13\n",
            "processing image:  14\n",
            "processing image:  15\n",
            "processing image:  16\n",
            "processing image:  17\n",
            "processing image:  18\n",
            "processing image:  19\n",
            "processing image:  20\n",
            "processing image:  21\n",
            "processing image:  22\n",
            "processing image:  23\n",
            "processing image:  24\n",
            "processing image:  25\n",
            "processing image:  26\n",
            "processing image:  27\n",
            "processing image:  28\n",
            "processing image:  29\n",
            "processing image:  30\n",
            "processing image:  31\n",
            "processing image:  32\n",
            "processing image:  33\n",
            "processing image:  34\n",
            "processing image:  35\n",
            "processing image:  36\n",
            "processing image:  37\n",
            "processing image:  38\n",
            "processing image:  39\n",
            "processing image:  40\n",
            "processing image:  41\n",
            "processing image:  42\n",
            "processing image:  43\n",
            "processing image:  44\n",
            "processing image:  45\n",
            "processing image:  46\n",
            "processing image:  47\n",
            "processing image:  48\n",
            "processing image:  49\n",
            "processing image:  50\n",
            "processing image:  51\n",
            "processing image:  52\n",
            "processing image:  53\n",
            "processing image:  54\n",
            "processing image:  55\n",
            "processing image:  56\n",
            "processing image:  57\n",
            "processing image:  58\n",
            "processing image:  59\n",
            "processing image:  60\n",
            "processing image:  61\n",
            "processing image:  62\n",
            "processing image:  63\n",
            "processing image:  64\n",
            "processing image:  65\n",
            "processing image:  66\n",
            "processing image:  67\n",
            "processing image:  68\n",
            "processing image:  69\n",
            "processing image:  70\n",
            "processing image:  71\n",
            "processing image:  72\n",
            "processing image:  73\n",
            "processing image:  74\n",
            "processing image:  75\n",
            "processing image:  76\n",
            "processing image:  77\n",
            "processing image:  78\n",
            "processing image:  79\n",
            "processing image:  80\n",
            "processing image:  81\n",
            "processing image:  82\n",
            "processing image:  83\n",
            "processing image:  84\n",
            "processing image:  85\n",
            "processing image:  86\n",
            "processing image:  87\n",
            "processing image:  88\n",
            "processing image:  89\n",
            "processing image:  90\n",
            "processing image:  91\n",
            "processing image:  92\n",
            "processing image:  93\n",
            "processing image:  94\n",
            "processing image:  95\n",
            "processing image:  96\n",
            "processing image:  97\n",
            "processing image:  98\n",
            "processing image:  99\n",
            "processing image:  100\n",
            "processing image:  101\n",
            "processing image:  102\n",
            "processing image:  103\n",
            "processing image:  104\n",
            "processing image:  105\n",
            "processing image:  106\n",
            "processing image:  107\n",
            "processing image:  108\n",
            "processing image:  109\n",
            "processing image:  110\n",
            "processing image:  111\n",
            "processing image:  112\n",
            "processing image:  113\n",
            "processing image:  114\n",
            "processing image:  115\n",
            "processing image:  116\n",
            "processing image:  117\n",
            "processing image:  118\n",
            "processing image:  119\n",
            "sample size:  266  faces\n",
            "time of encoding generation: 102.94077038764954  sec\n",
            "time of clustering: 0.004381418228149414  sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in labels:\n",
        "  if i <0:\n",
        "    count+=1\n",
        "print(f\"Total unclasifiable faces : {count}\")\n",
        "print(\"Percentage of unclassified samples: \",100*count/len(labels),\"%\")\n",
        "print(\"Classifying Efficiency: \",100-(100*count/len(labels)),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-mVAib6_W36",
        "outputId": "ffe74c64-b02b-4562-9f70-e4636f99c1da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unclasifiable faces : 77\n",
            "Percentage of unclassified samples:  28.94736842105263 %\n",
            "Classifying Efficiency:  71.05263157894737 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for labelID in labelIDs:\n",
        "        # if labelID<0:\n",
        "            # continue\n",
        "        allIdxs = np.where(labels == labelID)[0]\n",
        "        idxs = np.random.choice(allIdxs, size=min(25, len(allIdxs)),\n",
        "    replace=False)\n",
        "        faces = []\n",
        "        for i in idxs:\n",
        "            imgpath = data[i][\"imagePath\"]\n",
        "            temp = imgpath.split(\"/\")[-1]\n",
        "            imgtype = temp.split(\"_\")[0]\n",
        "            image = cv2.imread(data[i][\"imagePath\"])\n",
        "            (top, right, bottom, left) = data[i][\"loc\"]\n",
        "            face = image[top:bottom, left:right]\n",
        "            face = cv2.resize(face, (96, 96))\n",
        "            faces.append(face)\n",
        "        montage = build_montages(faces, (96, 96), (5, 5))[0]\n",
        "        cv2.imwrite(f\"/content/summerProj/static/faces/{labelID}.jpg\",montage)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9128i36ABCO2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labelIDs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8roY1sDbyIy",
        "outputId": "1d6c1e1f-0e5c-4d7c-c299-4beb0eba2953"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpGRiu2kb4EL",
        "outputId": "bcbef870-b4ac-48d9-972b-d07c6cce89f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1 -1  9  2 -1  3  4  4  3  5 -1  0 -1  5  0  9 -1  6 -1  0  1 -1  0\n",
            "  7  2  8  0  3 -1  0 -1  1  0 -1  9  7  8 12  6 10  0  5 -1 11 -1 -1  9\n",
            "  7  8  6 -1  5 -1 -1  1  6  5  4  3  7  0  7  0  0  7 -1 -1  4  3  7  0\n",
            " -1  3  4  0  1 -1 -1  7  3  4  0  7  0  7 11  0  1 -1  9  6  0  4  3  0\n",
            "  3  4  9 -1 -1  0  7 10  6 -1 -1  0  0  2  7  9 12 -1 11 -1 -1 11 -1  0\n",
            "  7  7  9  0 -1  1  7  0 -1 10  7  8  6 12  2  0  0  2 10  3  4  0  1  7\n",
            "  0 -1  7  0  7  7  0  2  6  5  2 -1  0  9 -1 12  0  7  9  0  1 -1 -1  0\n",
            " -1 -1  7 -1 -1  3  4  7  8  9 10  0  3  4  4  3  4  3 -1 -1  0  5  0  9\n",
            " -1  6 -1  1  0 -1 -1  0  1  5 -1 -1  5 -1 -1 -1  0 -1 -1  4  3  3  4  5\n",
            "  7  0  0  6  0 11 -1 -1  0 -1  9 -1 -1  7 -1  0 -1 -1 -1 -1 -1 -1  1  7\n",
            " -1 -1  2  7  6 10  0  8 12  7 -1  0  1 -1 -1  1 -1  0  0 -1 -1 -1  0  0\n",
            " -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(encodings))\n",
        "print(\"here first number is the number of faces and second number is\\nthe number of dimensions of the encoding data\")\n",
        "print(\"Like for 2d data there would be only two x,y and for 3d there would be x,y,z\\nsimilarily there are 128 dimensions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j9hdzy1b_cW",
        "outputId": "398badf3-d19e-4df5-b493-52f61f54d6fc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(266, 128)\n",
            "here first number is the number of faces and second number is\n",
            "the number of dimensions of the encoding data\n",
            "Like for 2d data there would be only two x,y and for 3d there would be x,y,z\n",
            "similarily there are 128 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOzfRt40ffSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}